{
    "seed": 42,
    "description": "Seq2Seq with Attention Model",
    "output_dir": "./checkpoints/",
    "checkpoints_dir": "seq2seq_with_attention",
    "cudnn_deterministic": true,
    "dataset": {
      "module": "data.multi30k",
      "main": "Multi30kData",
      "args": {
        "include_lengths": false
      }
    },
    "model_encoder": {
        "module": "model.seq2seq_with_attention",
        "main": "Encoder",
        "args": {
            "input_dim": 0,
            "emb_dim": 256,
            "enc_hid_dim": 512,
            "dec_hid_dim": 512,
            "dropout": 0.5
        }
    },
    "model_attention": {
        "module": "model.seq2seq_with_attention",
        "main": "Attention",
        "args": {
            "enc_hid_dim": 512,
            "dec_hid_dim": 512
        }
    },
    "model_decoder": {
        "module": "model.seq2seq_with_attention",
        "main": "Decoder",
        "args": {
            "output_dim": 0,
            "emb_dim": 256,
            "enc_hid_dim": 512,
            "dec_hid_dim": 512,
            "dropout": 0.5,
            "attention": ""
        }
    },
    "seq2seq_model": {
        "module": "model.seq2seq_with_attention",
        "main": "Seq2Seq"
    },
    "optimizer": {
        "lr": 0.0001,
        "beta1": 0.9,
        "beta2": 0.999,
        "weight_decay" : 0.0001
    },
    "loss_function": {
        "module": "model.loss",
        "main": "binary_cross_entropy",
        "args": {
            "ignore_index": ""
        }
    },
    "trainer": {
        "module": "trainer.seq2seq_trainer",
        "main": "Trainer",
        "epochs": 10,
        "batch_size": 2,
        "clip": 1,
        "save_checkpoint_interval": 1,
        "test": {
            "interval": 1,
            "find_max": true
        }
    },
    "data": {
        "sort_within_batch": false
    }
}
